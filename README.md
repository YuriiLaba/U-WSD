# Contextual embeddings for Ukrainian: A large language model approach to word sense disambiguation


[![Download model ü§ó ](https://img.shields.io/badge/Download%20Model-%F0%9F%A4%97%20Model-yellow)](https://huggingface.co/lang-uk/ukr-paraphrase-multilingual-mpnet-base)

This repository is an official implementation of paper
[Contextual Embeddings for Ukrainian: A Large Language Model Approach to Word Sense Disambiguation](https://aclanthology.org/2023.unlp-1.2/) (Laba et al., UNLP 2023 at EACL).

## WSD task overview
Word Sense Disambiguation (WSD) task involves identifying a polysemic word‚Äôs correct meaning in a given context.

## Solution overview

In our approach to the Word Sense Disambiguation (WSD) task, we fine-tuned the **ConEFU** model for the Ukrainian language. **ConEFU** is based on the [S-BERT model](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) and was fine-tuned using an unsupervised triplet dataset built on [UberText2.0](https://lang.org.ua/en/ubertext/). We employed TripletMarginLoss during fine-tuning to maximize the separation between correct and incorrect senses of homonyms.

The model was validated on a WSD dataset based on the [–°–õ–û–í–ù–ò–ö –£–ö–†–ê–á–ù–°–¨–ö–û–á –ú–û–í–ò](https://sum20ua.com). To the best of our knowledge, this is the first dataset used to validate the WSD task in Ukrainian.

**ConEFU** can be utilized to generate high-quality embeddings for the Ukrainian language. It is available on [Hugging Face](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2).



## Metrics
## Metrics
| Model                          | Overall Acc. | Noun Acc. | Verb Acc. | Adj. Acc. | Adv. Acc. |
|--------------------------------|--------------|-----------|-----------|-----------|-----------|
| Babelfy Baseline               | 0.526        | -         | -         | -         | -         |
| PMMBv2                         | 0.735        | 0.767     | 0.668     | 0.752     | 0.593     |
| ConEFU ‚àº190K Triplets          | 0.770        | 0.819     | 0.685     | 0.743     | 0.562     |
| ConEFU ‚àº1.2M Triplets          | 0.778        | **0.825** | **0.698** | **0.761** | 0.531     |
| ConEFU ‚àº1.2M Triplets Filtered* | **0.779** | 0.824     | 0.693     | 0.759     | **0.607** |

(**\***) Filtering refers to removing triplets where the difference between the cosine similarity of the anchor and positive examples, and the anchor and negative examples, is less than 0.3.

## Datasets

### The WSD evaluation dataset

- **Lemma**: The base form of the word.
- **Lexical Meanings**: List of distinct meanings associated with the lemma.
- **Usage Examples**: Sentences demonstrating how each meaning is used in context.

| Lemma | Lexical Meanings | Usage Examples |
|-------|-------|----------|
| –∫–æ—Å–∞  | ['–ó–∞–ø–ª–µ—Ç–µ–Ω–µ –≤–æ–ª–æ—Å—Å—è', '–î–æ–≤–≥–µ –≤–æ–ª–æ—Å—Å—è'] | ['–Ø–∫—Ä–∞–∑ –ø—ñ–¥ —Å—Ç–∞—Ä–æ—é –≤–∏—à–Ω–µ—é —Å—Ç–æ—è–ª–∞ –¥—ñ–≤—á–∏–Ω–∞, —Ö–æ—Ä–æ—à–∞, —è–∫ –∑–æ—Ä—è —è—Å–Ω–∞; —Ä—É—Å–∞ –∫–æ—Å–∞ –Ω–∏–∂—á–µ –ø–æ—è—Å–∞', '–û—á—ñ –≤ –Ω–µ—ó –±—É–ª–∏ –≤–µ–ª–∏–∫—ñ, –¥–≤—ñ —á–æ—Ä–Ω—ñ –∫–æ—Å–∏, –ø–µ—Ä–µ–∫–∏–Ω—É—Ç—ñ –Ω–∞–ø–µ—Ä–µ–¥, –æ–±—Ä–∞–º–ª—è–ª–∏ –ª–∏—Ü–µ'] |
| –∫–æ—Å–∞  | ["–°—ñ–ª—å—Å—å–∫–æ–≥–æ—Å–ø–æ–¥–∞—Ä—Å—å–∫–µ –∑–Ω–∞—Ä—è–¥–¥—è –¥–ª—è –∫–æ—Å—ñ–Ω–Ω—è —Ç—Ä–∞–≤–∏, –∑–µ—Ä–Ω–æ–≤–∏—Ö, —â–æ –º–∞—î —Ñ–æ—Ä–º—É –≤—É–∑—å–∫–æ–≥–æ –∑—ñ–≥–Ω—É—Ç–æ–≥–æ –ª–µ–∑–∞, –ø—Ä–∏–∫—Ä—ñ–ø–ª–µ–Ω–æ–≥–æ –¥–æ –∫—ñ—Å—Å—è –¥–µ—Ä–µ–≤'—è–Ω–æ–≥–æ –¥–µ—Ä–∂–∞–∫–∞"] | ['–°–≤—ñ–¥–æ–∫ —Å–ª–∞–≤–∏, –¥—ñ–¥—ñ–≤—â–∏–Ω–∏ –ó –≤—ñ—Ç—Ä–æ–º —Ä–æ–∑–º–æ–≤–ª—è—î, –ê –≤–Ω—É–∫ –∫–æ—Å—É –Ω–µ—Å–µ –≤ —Ä–æ—Å—É, –ó–∞ –Ω–∏–º–∏ —Å–ø—ñ–≤–∞—î', '–ö–æ—Å–∞—Ä—ñ –∫–æ—Å—è—Ç—å, –ê –≤—ñ—Ç–µ—Ä –ø–æ–≤—ñ–≤–∞—î, –®–æ–≤–∫–æ–≤–∞ —Ç—Ä–∞–≤–∞ –ù–∞ –∫–æ—Å–∏ –ø–æ–ª—è–≥–∞—î'] |
| –∫–æ—Å–∞  | ['–ü—ñ—â–∞–Ω–∞ –≤—É–∑—å–∫–∞, –¥–æ–≤–≥–∞ —á–∞—Å—Ç–∏–Ω–∞ —Å—É—Ö–æ–¥–æ–ª—É, —â–æ –≤—ñ–¥–æ–∫—Ä–µ–º–ª—é—î –≤—ñ–¥ –≤—ñ–¥–∫—Ä–∏—Ç–æ–≥–æ –º–æ—Ä—è –±—É—Ö—Ç—É, –æ–∑–µ—Ä–æ –∞–±–æ –∑–∞—Ç–æ–∫—É; –º–∏—Å'] | ['–ß–æ–≤–µ–Ω –ø–æ–≤–µ—Ä–Ω—É–≤ –∑–∞ –≥–æ—Å—Ç—Ä–∏–π —Ä—ñ–≥ –ø—ñ—Å–∫—É–≤–∞—Ç–æ—ó –∫–æ—Å–∏ —ñ –≤—Å—Ç—É–ø–∏–≤ —É –ß–æ—Ä–Ω–µ –º–æ—Ä–µ', '–°–∫—ñ–ª—å–∫–∏ –æ–∫–æ–º —Å–∫–∏–Ω–µ—à ‚Äì –ª–µ–ª—ñ—î –î–Ω—ñ–ø—Ä–æ, –≤–∏–≥–∏–Ω–∞—é—á–∏—Å—å –ø–æ–º–µ–∂–∏ –≥–æ—Ä–∞–º–∏, —Ç–∏—Ö–æ –º–∏—é—á–∏ –ø—ñ—Å–∫—É–≤–∞—Ç—ñ –∫–æ—Å–∏'] |
| –∫–æ—Å–∞  | ['–°–µ–ª–µ–∑—ñ–Ω–∫–∞'] | ['–ö–æ—Å–∞ —Å–≤–∏–Ω—è—á–∞, —â–æ –∫–æ–ª–æ –ø–µ—á—ñ–Ω–∫–∏, –¥–æ–≤–≥–µ–Ω—å–∫–∞'] |
| –∫–æ—Å–∞  | ['–ü—ñ–≤–¥–µ–Ω–Ω–æ–∞—Ñ—Ä–∏–∫–∞–Ω—Å—å–∫–∏–π –µ—Ç–Ω–æ—Å, —â–æ –Ω–∞–ª–µ–∂–∏—Ç—å –¥–æ –≥—Ä—É–ø–∏ –Ω–∞—Ä–æ–¥—ñ–≤ –±–∞–Ω—Ç—É'] | ['–ó–∞ –≥–µ–Ω–µ–∞–ª–æ–≥—ñ—á–Ω–∏–º–∏ –ø–µ—Ä–µ–∫–∞–∑–∞–º–∏, –∫–æ—Å–∞ —î –Ω–∞—â–∞–¥–∫–∞–º–∏ –ª–µ–≥–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≤–æ–∂–¥—è –ö–æ—Å–∞, –≤—ñ–¥ —ñ–º–µ–Ω—ñ —è–∫–æ–≥–æ –π –ø–æ—Ö–æ–¥–∏—Ç—å –Ω–∞–∑–≤–∞ –µ—Ç–Ω–æ—Å—É', '–£ 1886 —Ä–æ—Ü—ñ –±—Ä–∏—Ç–∞–Ω—Å—å–∫–∏–π –¥–æ—Å–ª—ñ–¥–Ω–∏–∫ –ì–µ–æ—Ä–≥ –¢—ñ–ª—å –≤–∏–¥–∞–≤ –∑–±—ñ—Ä–∫—É –∫–∞–∑–æ–∫ —ñ –±–∞–π–æ–∫ –∫–æ—Å–∞'] |

You can access the WSD evaluation dataset [here](placeholder) or generate it on your own using U-WSD framework:

```python
from src.utils_data import read_and_transform_data

data = read_and_transform_data('sum_14_final.jsonlines', homonym=True)
```

### The WSD train dataset

- **Anchor**: A sentence containing the target homonym lemma in its specific meaning.
- **Positive**: A sentence containing the target homonym lemma with the same meaning as the anchor.
- **Negative**: A sentence containing the target homonym lemma with a different meaning from the anchor.
- **Positive Score**: Cosine similarity score between the anchor and the positive sentence.
- **Negative Score**: Cosine similarity score between the anchor and the negative sentence.


| Anchor                                                                                                     | Positive                                                      | Negative                                                                                                   | Positive Score | Negative Score |
|------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|----------------|----------------|
| –Ø–∫ –Ω–∞—Å–ª—ñ–¥–æ–∫ - –ë–µ—Ä–¥—è–Ω—Å—å–∫–∞ <ins>**–∫–æ—Å–∞**</ins> —É —Ä–æ–∑–ø–∞–ª –∫—É—Ä–æ—Ä—Ç–Ω–æ–≥–æ —Å–µ–∑–æ–Ω—É –∑–∞–ª–∏—à–∏–ª–∞—Å—è –≤–∑–∞–≥–∞–ª—ñ –±–µ–∑ –ø–∏—Ç–Ω–æ—ó –≤–æ–¥–∏".            | –í–æ–¥–∞ —á–∏—Å—Ç–∞, –ø—ñ—â–∞–Ω–∞ <ins>**–∫–æ—Å–∞**</ins> –¥–æ—Å–∏—Ç—å –¥–∞–ª–µ–∫–æ –∑–∞—Ö–æ–¥–∏—Ç—å —É –º–æ—Ä–µ.       | –ë–∞—Ç—å–∫–æ, —è–∫–∏–π –ø–æ–º–µ—Ä, –∫–æ–ª–∏ –ú—ñ—Ä—ñ–∞–º –±—É–ª–æ 6 —Ä–æ–∫—ñ–≤, –Ω–∞–ª–µ–∂–∞–≤ –¥–æ –Ω–∞—Ä–æ–¥—É <ins>**–∫–æ—Å–∞**</ins>.                                     | 0.712      | 0.351     |
| –ê–≥—Ä–∞—Ä—ñ—ó –ø—Ä–∏–π—à–ª–∏ –¥–æ –ê–∑–∞—Ä–æ–≤–∞ –∑ –≤–∏–ª–∞–º–∏ —ñ <ins>**–∫–æ—Å–∞–º–∏**</ins> –ë–ª–∏–∑—å–∫–æ –ø—ñ–≤—Ç–æ—Ä–∏ —Ç–∏—Å—è—á—ñ –∞–≥—Ä–∞—Ä—ñ—ó–≤ –ø—ñ–∫–µ—Ç—É–≤–∞–ª–∏ –ö–∞–±—ñ–Ω–µ—Ç –º—ñ–Ω—ñ—Å—Ç—Ä—ñ–≤.  | –ü–æ–ª–æ–≤–∏–Ω–∞ –≤—ñ–π—Å—å–∫–∞ –±—É–ª–∞ –æ–∑–±—Ä–æ—î–Ω–∞ –≤–∏–ª–∞–º–∏, <ins>**–∫–æ—Å–∞–º–∏**</ins> —ñ —Å–æ–∫–∏—Ä–∞–º–∏.     | –ù–∞ <ins>**–∫–æ—Å—ñ**</ins>, –æ–∫—Ä—ñ–º –∫—Ä–∞—î–≤–∏–¥—ñ–≤, –º–æ—Ä—è –π –ø–ª—è–∂—ñ–≤, –º–æ–∂–Ω–∞ —Ç–∞–∫–æ–∂ –∑–∞—Ö–æ–ø–ª—é—é—á–µ –ø–æ—Ä–∏–±–∞–ª–∏—Ç–∏.                                | 0.628      | 0.324     |
| –°–∞–º–µ –≤ —Ü—ñ–π –≤–µ—Ä—Å—ñ—ó —É –õ–∞—Ä–∏ –ö—Ä–æ—Ñ—Ç –∑'—è–≤–ª—è—î—Ç—å—Å—è <ins>**–∫–æ—Å–∞**</ins>.                                                          | –ê–ª–µ –æ—Å—å –∑'—è–≤–∏–ª–∞—Å—è –¥—ñ–≤—á–∏–Ω–∫–∞ –∑ <ins>**–∫–æ—Å–æ—é**</ins> –Ω–∞ –≥–æ–ª–æ–≤—ñ.                | –ó–æ–≤–Ω—ñ—à–Ω—ñ –ü—ñ–≤–Ω—ñ—á–Ω–æ-–§—Ä–∏–∑—å–∫—ñ –ø—ñ—â–∞–Ω—ñ <ins>**–∫–æ—Å–∏**</ins>  –Ø–ø–∑–∞–Ω–¥  –ù–æ—Ä–¥–µ—Ä–æ–æ–≥–∑–∞–Ω–¥  –ó—é–¥–µ—Ä–æ–æ–≥–∑–∞–Ω–¥  –ö–Ω—ñ–ø–∑–∞–Ω–¥  –Æ–Ω–≥–Ω–∞–º–µ–Ω–∑–∞–Ω–¥          | 0.773      | 0.385       |

Training dataset is being generated in unsupervised way. To generate it on your own run the following scripts:
```bash
python3 collect_ubertext_sentences.py
python3 collect_triplets.py
```
The dataset used in our paper is available for access [here](https://drive.google.com/drive/folders/1uY3nOYba-1fVpe_7s_Vj8P9MNawukuw-?usp=sharing).


## How to reproduce the results
### Step 1: Preparation
1. run collect_ubertext_senteces.py - will generate lemma -> sentences that contain that lemma

2. run collect_triplets.py - generate triplets

3. process sum (main.py)

### Step 2: Train
4. run run_fine_tuning.py

### Step 3: Evaluation
![Evaluation strategy visualization](images/prediction_diagram.png)
*Figure 1: Evaluation strategy visualization.*

5. run word sence predictor (main.py)

## Citation

```
@inproceedings{laba-etal-2023-contextual,
    title = "Contextual Embeddings for {U}krainian: A Large Language Model Approach to Word Sense Disambiguation",
    author = "Laba, Yurii  and
      Mudryi, Volodymyr  and
      Chaplynskyi, Dmytro  and
      Romanyshyn, Mariana  and
      Dobosevych, Oles",
    editor = "Romanyshyn, Mariana",
    booktitle = "Proceedings of the Second Ukrainian Natural Language Processing Workshop (UNLP)",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.unlp-1.2",
    doi = "10.18653/v1/2023.unlp-1.2",
    pages = "11--19"
}
```


TODOs:
1. Publish paper on papers with code
2. Publish WSD eval dataset and link it
  - Generate WSD Eval dataset
3. Go through the code, do high priority refactoring (like in src folder), create main scripts (main train, prepare and eval. Maiby in separate module)
  - check fine_tune_pytorch and remove it
4. Add brief documentation to each class/function
5. Improve project structure (like badly_predicted.py)
6. Fix train seeds
7. Generate new datasets (triplets and wsd_eval) and fine tune model
8. Check number of sentences collected per lemma
